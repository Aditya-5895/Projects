{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Intelligent Chat-Bot .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTqWqj8pC8/msSbJjao3ac",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bc0e15a68f54c0f98725244c5a38355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e58a3cf51f544168083dba2fb26d1d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_902b710cade64add8e508e0dfd3dec30",
              "IPY_MODEL_1f10204c46d34e32bb4a3af4dedefa42"
            ]
          }
        },
        "8e58a3cf51f544168083dba2fb26d1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "902b710cade64add8e508e0dfd3dec30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5afc714e62d0456da9bab13a2026fa33",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 305584576,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 305584576,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73022c1d832847bc94bc2cd8eddd7603"
          }
        },
        "1f10204c46d34e32bb4a3af4dedefa42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f28a07626c4e47b180e9c8fa2a7f5e37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 306M/306M [00:23&lt;00:00, 12.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_517519831f934e08afb18f426fff0cf9"
          }
        },
        "5afc714e62d0456da9bab13a2026fa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73022c1d832847bc94bc2cd8eddd7603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f28a07626c4e47b180e9c8fa2a7f5e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "517519831f934e08afb18f426fff0cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya-5895/Projects/blob/main/Intelligent_Chat_Bot_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unNrQA-gZEN5",
        "outputId": "e47f6742-b5a0-42a9-e8cc-d216c44f9b14"
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 7.2MB/s \n",
            "\u001b[?25hCollecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hCollecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.8MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2020.12.5)\n",
            "Building wheels for collected packages: jieba3k, tinysegmenter, feedfinder2, sgmllib3k\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398406 sha256=a653ab8aa86768964257d199ec1a5416d8c0c19ceaa36cc92b2b4c57b95ebf0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13538 sha256=4eb1a482cb6ee9951a0ab2d2501c8d4c453b89693d4272163d1fc7488046038e\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3358 sha256=92acf82c6dca924e700b0ffdb5ffbcf932333cd38b54a8027278c83a8339f9ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=7e0e39f65997897f28af3367e34e448e047f9e05b1cd487b932260120f238090\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built jieba3k tinysegmenter feedfinder2 sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, requests-file, tldextract, jieba3k, cssselect, tinysegmenter, feedfinder2, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IscfoELsZkqz",
        "outputId": "b0b5a292-f0c3-4413-9ff4-d18c65cd2d0b"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/75/df441011cd1726822b70fbff50042adb4860e9327b99b346154ead704c44/sentence-transformers-1.2.0.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.9MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 34.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (8.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.0-cp37-none-any.whl size=123339 sha256=89565edd19dfc90e41ac02225e3b8ac6e767fd49c47a054b304fef6e2d8db20b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/06/f7/faaa96fdda87462b4fd5c47b343340e9d5531ef70d0eef8242\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 sentence-transformers-1.2.0 sentencepiece-0.1.95 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1bc0e15a68f54c0f98725244c5a38355",
            "8e58a3cf51f544168083dba2fb26d1d9",
            "902b710cade64add8e508e0dfd3dec30",
            "1f10204c46d34e32bb4a3af4dedefa42",
            "5afc714e62d0456da9bab13a2026fa33",
            "73022c1d832847bc94bc2cd8eddd7603",
            "f28a07626c4e47b180e9c8fa2a7f5e37",
            "517519831f934e08afb18f426fff0cf9"
          ]
        },
        "id": "Z5gGz8Xwjt_M",
        "outputId": "b125aab1-c0a6-4a29-96e8-e4d2f2a71659"
      },
      "source": [
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "Sbert_model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc0e15a68f54c0f98725244c5a38355",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=305584576.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzxzI7hlasir"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XicsFHH6VpAw",
        "outputId": "74512414-5486-4080-b91f-5d2f102af86d"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBKV6c5nB55-"
      },
      "source": [
        "commands = ['convert and save all these text into a pdf ',\n",
        "            'how many number of lines are there ',\n",
        "            'summerise the page',\n",
        "            'give all the sentence encoding as an array']\n",
        "            \n",
        "encoded_commands = Sbert_model.encode(commands)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nBaVIgbyJ68W",
        "outputId": "d22d497a-a9b3-49a2-ecc3-f81a7a16628e"
      },
      "source": [
        "encd = Sbert_model.encode('how long the page is')\n",
        "idx = np.argmax(cosine_similarity([encd],bot.commands).flatten())\n",
        "commands[idx]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'summerise the page'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngZY-xz2LNED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlfXU9UpK95M",
        "outputId": "76ad4bf3-c773-4262-8529-bcee630865cf"
      },
      "source": [
        "cosine_similarity(encoded_commands,bot.commands)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8489856 , 0.09018158, 0.38468635, 0.49352527],\n",
              "       [0.14085528, 1.        , 0.24790281, 0.1847967 ],\n",
              "       [0.39187402, 0.16760625, 0.78454757, 0.23895857],\n",
              "       [0.5632971 , 0.18479677, 0.34465194, 1.0000002 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxXr5Jf2Ymky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f5210c1-6105-44ee-dc55-f71cce1ba90e"
      },
      "source": [
        "emb = Sbert_model.encode('how long the page is')\n",
        "sim = np.argmax(cosine_similarity([emb],encoded_commands).flatten())\n",
        "commands[sim]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'how many number of lines are there '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlwcBn-5klgg"
      },
      "source": [
        "def EuclidienDist(cm):\n",
        "    try:\n",
        "        cm = cm.toarray()\n",
        "    except:\n",
        "        pass\n",
        "    return np.linalg.norm(cm[-1] - cm ,axis=1)\n",
        "\n",
        "def CosineSimilarity(cm):\n",
        "    # print(cm)\n",
        "    q = cm[-1]\n",
        "    try:\n",
        "        similarity_scores = cosine_similarity([q],cm)\n",
        "    except:\n",
        "        similarity_scores = cosine_similarity(q,cm)\n",
        "    try:\n",
        "        similarity_scores = similarity_scores.flatten()\n",
        "        # print(similarity_scores.shape)\n",
        "        return similarity_scores\n",
        "    except:\n",
        "        return similarity_scores\n",
        "\n",
        "BagOfWords_model = CountVectorizer()\n",
        "TfIdf_model = TfidfVectorizer()\n",
        "\n",
        "class Chatbot():\n",
        "    def __init__(self):\n",
        "        \n",
        "        article = Article(input(\"Please Enter the website link : \"))\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        article.nlp()\n",
        "        self.summary = article.summary\n",
        "\n",
        "        commands = ['convert and save all these text into a word file ',\n",
        "            'how many number of lines are there ',\n",
        "            'please summarise the page',\n",
        "            'give all the sentence encoding as an array']\n",
        "        self.commands = Sbert_model.encode(commands)\n",
        "\n",
        "        similarity = int(input(\"Enter the matching : \\n1. Cosine Similarity \\n2. Euclidien Distance\\n\"))\n",
        "        self.similarity = CosineSimilarity if similarity ==1 else EuclidienDist\n",
        "\n",
        "        self.exit_list = ['exit', 'see you later', 'bye', 'quit', 'break','by','ok by', 'stop','tata']\n",
        "\n",
        "        self.bot_greetings = ['Howdy!', 'Hi!', 'Hello!', 'Greetings!']\n",
        "        self.user_greetings = ['hi', 'hey','hy', 'hello', 'greetings', 'wassup']\n",
        "\n",
        "        corpus = article.text\n",
        "        self.text = corpus\n",
        "        sentence_list = nltk.sent_tokenize(corpus)\n",
        "        self.sentence_list = sentence_list\n",
        "\n",
        "        self.encoding = int(input(\"Enter encoding :\\n1. CounterVectorizer(Bag of Words)\\n2. Tf-Idf\\n3. SentenceBert\\n\"))\n",
        "        # if self.encoding ==1:\n",
        "        #     self.sentence_encode = BagOfWords_model.fit_transform(sentence_list)\n",
        "        # elif self.encoding ==2:\n",
        "        #     self.sentence_encode = TfIdf_model.fit_transform(sentence_list)\n",
        "        if self.encoding ==3:\n",
        "            self.sentence_encode = Sbert_model.encode(sentence_list)\n",
        "            # print(self.sentence_encode.shape)\n",
        "    def greeting_response(self):\n",
        "        self.user_inp = self.user_inp.lower()\n",
        "        for word in self.user_inp.split():\n",
        "            if word in self.user_greetings:\n",
        "                return random.choice(self.bot_greetings)\n",
        "\n",
        "    def bot_response(self):\n",
        "        self.sentence_list.append(self.user_inp)\n",
        "        if self.encoding ==3:\n",
        "            emb = Sbert_model.encode(self.user_inp)\n",
        "            emb = emb.reshape(1,len(emb))\n",
        "            # print(emb.shape)\n",
        "            self.sentence_encode = np.append(self.sentence_encode , emb ,axis=0)\n",
        "        else:\n",
        "            if self.encoding ==1:\n",
        "                emb = BagOfWords_model.fit_transform(self.sentence_list)\n",
        "            elif self.encoding ==2:\n",
        "                emb = TfIdf_model.fit_transform(self.sentence_list)\n",
        "            self.sentence_encode = emb\n",
        "\n",
        "        # print(len(self.sentence_encode))\n",
        "        similarity_scores = self.similarity(self.sentence_encode)\n",
        "        index = np.argsort(similarity_scores)[::-1]\n",
        "        index = index[1:]\n",
        "        response = 0\n",
        "        bot_response = \" \"\n",
        "        \n",
        "        j = 0\n",
        "        for i in index:\n",
        "            if similarity_scores[i] > 0.0:\n",
        "                bot_response = bot_response+' '+self.sentence_list[i]\n",
        "                response = 1\n",
        "                j += 1\n",
        "            if j > 2:\n",
        "                break\n",
        "            if response == 0:\n",
        "                bot_response = bot_response+' '+\"I apologize, I don't understand / Your query is not in given in this Site.\"\n",
        "            self.sentence_encode = self.sentence_encode[:-1]\n",
        "            self.sentence_list.remove(self.user_inp)\n",
        "            return bot_response\n",
        "\n",
        "    def command(self):\n",
        "\n",
        "        encd = Sbert_model.encode(self.user_inp)\n",
        "        idx = np.argmax(cosine_similarity([encd],self.commands).flatten())\n",
        "        if idx == 0:\n",
        "            my_file = open(\"webpage.txt\", \"w+\")\n",
        "            my_file.write(self.text)\n",
        "            my_file.close()\n",
        "        elif idx == 1:\n",
        "            print(\"The no of lines in this webpage are : \",len(self.sentence_list))\n",
        "        elif idx == 2:\n",
        "            print(self.summary)\n",
        "        elif idx == 3:\n",
        "            df = pd.DataFrame(self.sentence_encode)\n",
        "            print(df)\n",
        "\n",
        "    def start(self):\n",
        "        self.mode = int(input(\"Choose one mode of action : \\n1. command \\n2. Question Answer\\n\"))\n",
        "        print(\"Welcome your settings has been saved . \\n Bot: Hi I am a Bot. \\n ask any question To exit, type [bye].\") \n",
        "\n",
        "        while(True):\n",
        "            self.user_inp = input(\" Aditya : \").lower()\n",
        "            if self.user_inp in self.exit_list:\n",
        "                print('Bot : Chat with you later, Have a good day')\n",
        "                break\n",
        "            if self.user_inp == \"command\":\n",
        "                self.mode = 1\n",
        "            elif self.user_inp == \"QA\":\n",
        "                self.mode = 2\n",
        "            else:\n",
        "                if self.greeting_response() != None:\n",
        "                    print('Bot : '+self.greeting_response(),'\\n')\n",
        "                elif self.mode == 2:\n",
        "                    print('Bot Response : '+self.bot_response(),'\\n')\n",
        "                elif self.mode ==1:\n",
        "                    self.command()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKKyew4kmwm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e95bef9-4a16-4ead-9940-6767d99d5dad"
      },
      "source": [
        "bot = Chatbot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please Enter the website link : https://en.wikipedia.org/wiki/History_of_India\n",
            "Enter the matching : \n",
            "1. Cosine Similarity \n",
            "2. Euclidien Distance\n",
            "1\n",
            "Enter encoding :\n",
            "1. CounterVectorizer(Bag of Words)\n",
            "2. Tf-Idf\n",
            "3. SentenceBert\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhAtbaq_oFeo",
        "outputId": "dee3160c-4ead-4a78-8b98-2d235a9dd0a1"
      },
      "source": [
        "bot.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose one mode of action : \n",
            "1. command \n",
            "2. Question Answer\n",
            "1\n",
            "Welcome your settings has been saved . \n",
            " Bot: Hi I am a Bot. \n",
            " ask any question To exit, type [bye].\n",
            " Aditya : how long the page is\n",
            "For post-1947 history, see History of India (1947–present)According to consensus in modern genetics anatomically modern humans first arrived on the Indian subcontinent from Africa between 73,000 and 55,000 years ago.\n",
            "The rule of the Chalukyas marks an important milestone in the history of South India and a golden age in the history of Karnataka.\n",
            "[240] The subsequent Mamluk dynasty of Delhi managed to conquer large areas of northern India, while the Khalji dynasty conquered most of central India while forcing the principal Hindu kingdoms of South India to become vassal states.\n",
            "[342] The Marathas remained a major power in India until their defeat in the Second and Third Anglo-Maratha Wars (1805–1818), which resulted in the East India Company controlling most of India.\n",
            "[361]East India Company rule in IndiaIndia under East India Company rule India in 1765 and 1805 showing East India Company Territories in pink.\n",
            " Aditya : by\n",
            "Bot : Chat with you later, Have a good day\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osxyg8CZKSqF",
        "outputId": "7bd6af60-28a8-4fb6-c2d1-16fa26cfc384"
      },
      "source": [
        "bot.commands"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.08351247,  0.0223561 , -0.11116273, ..., -0.0755427 ,\n",
              "        -0.00819497,  0.35946053],\n",
              "       [ 0.3602669 ,  0.1979391 , -0.18489434, ...,  0.43363312,\n",
              "        -0.14849584,  0.15083382],\n",
              "       [-0.05968295, -0.2101811 , -0.04385803, ...,  0.00238987,\n",
              "         0.25738528, -0.04942211],\n",
              "       [ 0.06915671, -0.06063669, -0.10771853, ..., -0.30033478,\n",
              "         0.03259272,  0.2672194 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbvM92tzi2AU",
        "outputId": "f2d78d2f-9aea-428f-997c-4b22ea569b99"
      },
      "source": [
        "bot.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose one mode of action : \n",
            "1. command \n",
            "2. Question Answer\n",
            "2\n",
            "Welcome your settings has been saved . \n",
            " Bot: Hi I am a Bot. \n",
            " ask any question To exit, type [bye].\n",
            " Aditya : hy\n",
            "Bot : Hello! \n",
            "\n",
            " Aditya :  who having lost her husband to a miscarriage\n",
            "Bot Response :   Ilango Adigal composed Silappatikaram, which is a non-religious work, that revolves around Kannagi, who having lost her husband to a miscarriage of justice at the court of the Pandyan dynasty, wreaks her revenge on his kingdom,[126] and Manimekalai, composed by Sīthalai Sāttanār, is a sequel to Silappatikaram, and tells the story of the daughter of Kovalan and Madhavi, who became a Buddhist Bikkuni. \n",
            "\n",
            " Aditya : The Shungas originated from\n",
            "Bot Response :   The Shungas originated from Magadha, and controlled areas of the central and eastern Indian subcontinent from around 187 to 78 BCE. \n",
            "\n",
            " Aditya : when Kanva dynasty of Magadha to establish their rule.\n",
            "Bot Response :   They had to compete with the Shunga Empire and then the Kanva dynasty of Magadha to establish their rule. \n",
            "\n",
            " Aditya : by\n",
            "Bot : Chat with you later, Have a good day\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}