{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YsVOgHyp_I-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "VCnMW7oMBvT9",
    "outputId": "61fde30a-0d8a-4656-dd2b-bc02dd94a5b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>zip</th>\n",
       "      <th>number_of_properties</th>\n",
       "      <th>submarket_name</th>\n",
       "      <th>building_class</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>completions</th>\n",
       "      <th>vac_pct</th>\n",
       "      <th>vacancy_chg_bps</th>\n",
       "      <th>asking_rent_pct_chg</th>\n",
       "      <th>abs_per_occ_stk_pct</th>\n",
       "      <th>construction_per_absorption</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>total_employment_pct_chg</th>\n",
       "      <th>office_employment</th>\n",
       "      <th>office_employment_pct_chg</th>\n",
       "      <th>industrial_employment</th>\n",
       "      <th>industrial_employment_pct_chg</th>\n",
       "      <th>households</th>\n",
       "      <th>households_pct_chg</th>\n",
       "      <th>population</th>\n",
       "      <th>population_pct_chg</th>\n",
       "      <th>household_avg_income</th>\n",
       "      <th>household_avg_income_pct_chg</th>\n",
       "      <th>Liking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>77072.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.482890</td>\n",
       "      <td>0.191542</td>\n",
       "      <td>0.526832</td>\n",
       "      <td>0.128822</td>\n",
       "      <td>0.790339</td>\n",
       "      <td>0.171594</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.296032</td>\n",
       "      <td>0.842993</td>\n",
       "      <td>0.136222</td>\n",
       "      <td>0.506133</td>\n",
       "      <td>0.141550</td>\n",
       "      <td>0.633837</td>\n",
       "      <td>0.112065</td>\n",
       "      <td>0.740644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>77072.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533708</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.528517</td>\n",
       "      <td>0.144279</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.129543</td>\n",
       "      <td>0.465509</td>\n",
       "      <td>0.182003</td>\n",
       "      <td>0.480693</td>\n",
       "      <td>0.270387</td>\n",
       "      <td>0.478249</td>\n",
       "      <td>0.153377</td>\n",
       "      <td>0.531209</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.608747</td>\n",
       "      <td>0.123029</td>\n",
       "      <td>0.613766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>77072.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.498099</td>\n",
       "      <td>0.184080</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.136126</td>\n",
       "      <td>0.509931</td>\n",
       "      <td>0.191225</td>\n",
       "      <td>0.467635</td>\n",
       "      <td>0.270045</td>\n",
       "      <td>0.551773</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.181168</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>0.679434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>77072.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.429658</td>\n",
       "      <td>0.191542</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.155840</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>0.208902</td>\n",
       "      <td>0.547502</td>\n",
       "      <td>0.290916</td>\n",
       "      <td>0.614353</td>\n",
       "      <td>0.182325</td>\n",
       "      <td>0.458679</td>\n",
       "      <td>0.196837</td>\n",
       "      <td>0.481167</td>\n",
       "      <td>0.143077</td>\n",
       "      <td>0.493555</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>77072.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297753</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.463878</td>\n",
       "      <td>0.184080</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>0.226653</td>\n",
       "      <td>0.544083</td>\n",
       "      <td>0.341987</td>\n",
       "      <td>0.701647</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.350930</td>\n",
       "      <td>0.211307</td>\n",
       "      <td>0.451953</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>0.631541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      zip  ...  household_avg_income_pct_chg  Liking\n",
       "0           7  77072.0  ...                      0.740644     0.0\n",
       "1           8  77072.0  ...                      0.613766     0.0\n",
       "2           9  77072.0  ...                      0.679434     0.0\n",
       "3          10  77072.0  ...                      0.493555     0.0\n",
       "4          11  77072.0  ...                      0.631541     0.0\n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TrainableData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "GBa2zoeeBz5u",
    "outputId": "8abca35c-91b0-4947-9d5d-c3c155114a08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_properties</th>\n",
       "      <th>submarket_name</th>\n",
       "      <th>building_class</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>completions</th>\n",
       "      <th>vac_pct</th>\n",
       "      <th>vacancy_chg_bps</th>\n",
       "      <th>asking_rent_pct_chg</th>\n",
       "      <th>abs_per_occ_stk_pct</th>\n",
       "      <th>construction_per_absorption</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>total_employment_pct_chg</th>\n",
       "      <th>office_employment</th>\n",
       "      <th>office_employment_pct_chg</th>\n",
       "      <th>industrial_employment</th>\n",
       "      <th>industrial_employment_pct_chg</th>\n",
       "      <th>households</th>\n",
       "      <th>households_pct_chg</th>\n",
       "      <th>population</th>\n",
       "      <th>population_pct_chg</th>\n",
       "      <th>household_avg_income</th>\n",
       "      <th>household_avg_income_pct_chg</th>\n",
       "      <th>Liking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.482890</td>\n",
       "      <td>0.191542</td>\n",
       "      <td>0.526832</td>\n",
       "      <td>0.128822</td>\n",
       "      <td>0.790339</td>\n",
       "      <td>0.171594</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.296032</td>\n",
       "      <td>0.842993</td>\n",
       "      <td>0.136222</td>\n",
       "      <td>0.506133</td>\n",
       "      <td>0.141550</td>\n",
       "      <td>0.633837</td>\n",
       "      <td>0.112065</td>\n",
       "      <td>0.740644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533708</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.528517</td>\n",
       "      <td>0.144279</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.129543</td>\n",
       "      <td>0.465509</td>\n",
       "      <td>0.182003</td>\n",
       "      <td>0.480693</td>\n",
       "      <td>0.270387</td>\n",
       "      <td>0.478249</td>\n",
       "      <td>0.153377</td>\n",
       "      <td>0.531209</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.608747</td>\n",
       "      <td>0.123029</td>\n",
       "      <td>0.613766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.498099</td>\n",
       "      <td>0.184080</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.136126</td>\n",
       "      <td>0.509931</td>\n",
       "      <td>0.191225</td>\n",
       "      <td>0.467635</td>\n",
       "      <td>0.270045</td>\n",
       "      <td>0.551773</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.181168</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>0.679434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.429658</td>\n",
       "      <td>0.191542</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.155840</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>0.208902</td>\n",
       "      <td>0.547502</td>\n",
       "      <td>0.290916</td>\n",
       "      <td>0.614353</td>\n",
       "      <td>0.182325</td>\n",
       "      <td>0.458679</td>\n",
       "      <td>0.196837</td>\n",
       "      <td>0.481167</td>\n",
       "      <td>0.143077</td>\n",
       "      <td>0.493555</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.255556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297753</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.463878</td>\n",
       "      <td>0.184080</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>0.226653</td>\n",
       "      <td>0.544083</td>\n",
       "      <td>0.341987</td>\n",
       "      <td>0.701647</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.350930</td>\n",
       "      <td>0.211307</td>\n",
       "      <td>0.451953</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>0.631541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_properties  submarket_name  ...  household_avg_income_pct_chg  Liking\n",
       "0              0.255556               0  ...                      0.740644     0.0\n",
       "1              0.255556               0  ...                      0.613766     0.0\n",
       "2              0.255556               0  ...                      0.679434     0.0\n",
       "3              0.255556               0  ...                      0.493555     0.0\n",
       "4              0.255556               0  ...                      0.631541     0.0\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0','zip'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Yn52KQ7XB1ql"
   },
   "outputs": [],
   "source": [
    "data = df.drop('Liking',axis=1)\n",
    "target = df['Liking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9sTocuFB3kf",
    "outputId": "02bd5369-47c9-45e8-a3a6-e3dd5f06799c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2665\n",
       "0.0     615\n",
       "Name: Liking, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Liking.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAmXSR74CB9D"
   },
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ROS52M8ACimO"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JN7YXyReB6m-"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S18R6WiKCFGG",
    "outputId": "c43075c1-3dcd-4ac7-c532-f8c5c81dc8bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([2665, 2665]))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(data,target)\n",
    "np.unique(y_sm,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PF4jMP21CIlW"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.3,stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "souy3Y8QDrZ1",
    "outputId": "80a15f0d-f154-4556-ccbd-4ce77b3fdc7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5330, 23)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZQfGZvDCnek",
    "outputId": "4ce55338-e059-4d76-ca05-54d501b98b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.6836 - accuracy: 0.5661 - val_loss: 0.6383 - val_accuracy: 0.5872\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6079 - val_loss: 0.6209 - val_accuracy: 0.5929\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6224 - val_loss: 0.6027 - val_accuracy: 0.5997\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6266 - val_loss: 0.5847 - val_accuracy: 0.6473\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.6526 - val_loss: 0.5562 - val_accuracy: 0.6735\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.6615 - val_loss: 0.5321 - val_accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.6853 - val_loss: 0.5128 - val_accuracy: 0.7017\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.6899 - val_loss: 0.5026 - val_accuracy: 0.7311\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.6977 - val_loss: 0.4876 - val_accuracy: 0.7298\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7156 - val_loss: 0.4786 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f861322be90>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_shape=(23,), activation='relu'),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# tf.keras.metrics.BinaryAccuracy(\n",
    "#     name=\"binary_accuracy\", dtype=None, threshold=0.5\n",
    "# )\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEyG6eFhGXZd",
    "outputId": "61b129d3-e4a9-4f0a-b635-8e5d6728ba22",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7497 - val_loss: 0.4194 - val_accuracy: 0.7517\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7478 - val_loss: 0.4182 - val_accuracy: 0.7624\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7505 - val_loss: 0.4164 - val_accuracy: 0.7630\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7478 - val_loss: 0.4194 - val_accuracy: 0.7649\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7550 - val_loss: 0.4144 - val_accuracy: 0.7636\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7467 - val_loss: 0.4151 - val_accuracy: 0.7555\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7545 - val_loss: 0.4220 - val_accuracy: 0.7611\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7491 - val_loss: 0.4116 - val_accuracy: 0.7661\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7537 - val_loss: 0.4145 - val_accuracy: 0.7605\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7566 - val_loss: 0.4112 - val_accuracy: 0.7655\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7526 - val_loss: 0.4104 - val_accuracy: 0.7674\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.7529 - val_loss: 0.4110 - val_accuracy: 0.7649\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.7623 - val_loss: 0.4103 - val_accuracy: 0.7611\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7572 - val_loss: 0.4099 - val_accuracy: 0.7580\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.7596 - val_loss: 0.4088 - val_accuracy: 0.7717\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7556 - val_loss: 0.4077 - val_accuracy: 0.7711\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7531 - val_loss: 0.4103 - val_accuracy: 0.7674\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7569 - val_loss: 0.4065 - val_accuracy: 0.7661\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7601 - val_loss: 0.4066 - val_accuracy: 0.7680\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.7566 - val_loss: 0.4041 - val_accuracy: 0.7736\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.7609 - val_loss: 0.4049 - val_accuracy: 0.7674\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.7682 - val_loss: 0.4052 - val_accuracy: 0.7705\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.7585 - val_loss: 0.4040 - val_accuracy: 0.7705\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.7590 - val_loss: 0.4024 - val_accuracy: 0.7742\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.7598 - val_loss: 0.4059 - val_accuracy: 0.7711\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.7636 - val_loss: 0.4055 - val_accuracy: 0.7611\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.7628 - val_loss: 0.4027 - val_accuracy: 0.7680\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.7625 - val_loss: 0.4079 - val_accuracy: 0.7649\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.7612 - val_loss: 0.4017 - val_accuracy: 0.7705\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7666 - val_loss: 0.4018 - val_accuracy: 0.7724\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7615 - val_loss: 0.3999 - val_accuracy: 0.7749\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7687 - val_loss: 0.3982 - val_accuracy: 0.7799\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7620 - val_loss: 0.4011 - val_accuracy: 0.7692\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.7711 - val_loss: 0.3996 - val_accuracy: 0.7767\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.7668 - val_loss: 0.3978 - val_accuracy: 0.7749\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.7703 - val_loss: 0.3984 - val_accuracy: 0.7717\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.7649 - val_loss: 0.3970 - val_accuracy: 0.7786\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.7617 - val_loss: 0.3961 - val_accuracy: 0.7742\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.7652 - val_loss: 0.3989 - val_accuracy: 0.7742\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7623 - val_loss: 0.3980 - val_accuracy: 0.7792\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.7727 - val_loss: 0.3951 - val_accuracy: 0.7749\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.7698 - val_loss: 0.3966 - val_accuracy: 0.7699\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.7641 - val_loss: 0.3980 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.7692 - val_loss: 0.3957 - val_accuracy: 0.7780\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.7741 - val_loss: 0.3960 - val_accuracy: 0.7774\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.7730 - val_loss: 0.3942 - val_accuracy: 0.7749\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.7703 - val_loss: 0.3936 - val_accuracy: 0.7767\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.7714 - val_loss: 0.3926 - val_accuracy: 0.7824\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.7700 - val_loss: 0.3932 - val_accuracy: 0.7780\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.7698 - val_loss: 0.3901 - val_accuracy: 0.7830\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.7751 - val_loss: 0.3926 - val_accuracy: 0.7786\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.7692 - val_loss: 0.3944 - val_accuracy: 0.7830\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.7730 - val_loss: 0.3944 - val_accuracy: 0.7780\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.7754 - val_loss: 0.3931 - val_accuracy: 0.7842\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.7698 - val_loss: 0.3926 - val_accuracy: 0.7786\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.7690 - val_loss: 0.3976 - val_accuracy: 0.7724\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.7690 - val_loss: 0.3919 - val_accuracy: 0.7811\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.7682 - val_loss: 0.3905 - val_accuracy: 0.7849\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.7722 - val_loss: 0.3924 - val_accuracy: 0.7799\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.7749 - val_loss: 0.3981 - val_accuracy: 0.7711\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.7757 - val_loss: 0.3890 - val_accuracy: 0.7799\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.7818 - val_loss: 0.3918 - val_accuracy: 0.7792\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.7708 - val_loss: 0.3891 - val_accuracy: 0.7849\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.7724 - val_loss: 0.3877 - val_accuracy: 0.7830\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.7727 - val_loss: 0.3895 - val_accuracy: 0.7842\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.7786 - val_loss: 0.3882 - val_accuracy: 0.7830\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.7759 - val_loss: 0.3894 - val_accuracy: 0.7811\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.7773 - val_loss: 0.3890 - val_accuracy: 0.7799\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.7813 - val_loss: 0.3867 - val_accuracy: 0.7855\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.7818 - val_loss: 0.3923 - val_accuracy: 0.7755\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.7749 - val_loss: 0.3878 - val_accuracy: 0.7861\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.7757 - val_loss: 0.3874 - val_accuracy: 0.7842\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.7781 - val_loss: 0.3884 - val_accuracy: 0.7811\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.7840 - val_loss: 0.3894 - val_accuracy: 0.7842\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.7743 - val_loss: 0.3873 - val_accuracy: 0.7836\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.7824 - val_loss: 0.3847 - val_accuracy: 0.7855\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.7826 - val_loss: 0.3844 - val_accuracy: 0.7824\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.7829 - val_loss: 0.3862 - val_accuracy: 0.7842\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.7786 - val_loss: 0.3829 - val_accuracy: 0.7905\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.7800 - val_loss: 0.3843 - val_accuracy: 0.7930\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.7834 - val_loss: 0.3804 - val_accuracy: 0.7899\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.7808 - val_loss: 0.3817 - val_accuracy: 0.7917\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.7858 - val_loss: 0.3848 - val_accuracy: 0.7874\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.7832 - val_loss: 0.3791 - val_accuracy: 0.7961\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.7952 - val_loss: 0.3778 - val_accuracy: 0.7942\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.7952 - val_loss: 0.3781 - val_accuracy: 0.7974\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.7944 - val_loss: 0.3766 - val_accuracy: 0.8061\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.7915 - val_loss: 0.3763 - val_accuracy: 0.8055\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.7915 - val_loss: 0.3734 - val_accuracy: 0.8211\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.7995 - val_loss: 0.3734 - val_accuracy: 0.8061\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.7971 - val_loss: 0.3693 - val_accuracy: 0.8293\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8001 - val_loss: 0.3683 - val_accuracy: 0.8249\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.7990 - val_loss: 0.3704 - val_accuracy: 0.8186\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.7984 - val_loss: 0.3661 - val_accuracy: 0.8218\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.7992 - val_loss: 0.3635 - val_accuracy: 0.8180\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.7952 - val_loss: 0.3612 - val_accuracy: 0.8218\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.7968 - val_loss: 0.3577 - val_accuracy: 0.8361\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8014 - val_loss: 0.3570 - val_accuracy: 0.8299\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8009 - val_loss: 0.3532 - val_accuracy: 0.8361\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8038 - val_loss: 0.3529 - val_accuracy: 0.8368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f861330f5d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sq3uUanlD7Gd",
    "outputId": "39a16c3c-a760-4988-8e32-f7dc66cfd33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3529030978679657, 0.8367729783058167]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WRSm7uxYFvp_"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "hUetGof9GAal",
    "outputId": "0bcde965-23de-4dad-bbc5-8f9156e5a02d",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8613340ad0>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = [1 if i>=0.5 else 0 for i in y_pred]\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VOcKKqh2GsRP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_neural_net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
